import React, { useState, useCallback, useRef, useEffect } from 'react'
import { useAppContext } from '../../App'
import { MicrophoneMonitor, MicrophoneStatus, MicrophoneAlert } from '../../services/MicrophoneMonitor'
import { AudioMixingService, MixingConfig, AudioLevels } from '../../services/AudioMixingService'
import { TrueDifferentialChunkGenerator, TrueDifferentialResult } from '../../services/TrueDifferentialChunkGenerator'
import { FileBasedRealtimeProcessor } from '../../services/FileBasedRealtimeProcessor' 
/**
 * ä¸‹éƒ¨ãƒ‘ãƒãƒ« - ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«
 * éŒ²éŸ³ãƒ»å†ç”Ÿãƒ»æ–‡å­—èµ·ã“ã—ç­‰ã®ä¸»è¦æ“ä½œã‚’æä¾›
 */

// ãƒ†ã‚¹ãƒˆç”¨: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—å¼·åˆ¶æœ‰åŠ¹åŒ–ãƒ•ãƒ©ã‚°
const FORCE_ENABLE_REALTIME_TRANSCRIPTION = true;

const BottomPanel: React.FC = () => {
  // ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã®é–¢æ•°ã‚’å–å¾—
  const { setFileList, setIsRecording: setGlobalIsRecording, setRecordingFile, setSelectedFile } = useAppContext()
  // éŒ²éŸ³é–¢é€£çŠ¶æ…‹
  const [isRecording, setIsRecording] = useState<boolean>(false)
  const [isPaused, setIsPaused] = useState<boolean>(false)
  const [recordingTime, setRecordingTime] = useState<number>(0)
  
  // ãƒ‡ãƒã‚¤ã‚¹é–¢é€£çŠ¶æ…‹
  const [availableDevices, setAvailableDevices] = useState<MediaDeviceInfo[]>([])
  const [selectedDevice, setSelectedDevice] = useState<string>('')
  const [inputType, setInputType] = useState<'microphone' | 'desktop' | 'stereo-mix' | 'mixing'>('microphone')
  
  // ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚­ãƒ£ãƒ—ãƒãƒ£é–¢é€£çŠ¶æ…‹
  const [desktopSources, setDesktopSources] = useState<any[]>([])
  const [selectedDesktopSource, setSelectedDesktopSource] = useState<string>('')
  
  // ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹é–¢é€£çŠ¶æ…‹
  const [systemAudioDevices, setSystemAudioDevices] = useState<MediaDeviceInfo[]>([])
  const [selectedSystemDevice, setSelectedSystemDevice] = useState<string>('')
  
  
  // ãƒã‚¤ã‚¯ç›£è¦–çŠ¶æ…‹
  const [micStatus, setMicStatus] = useState<MicrophoneStatus | null>(null)
  const [micAlerts, setMicAlerts] = useState<MicrophoneAlert[]>([])
  
  // ãƒŸã‚­ã‚·ãƒ³ã‚°é–¢é€£çŠ¶æ…‹
  const [mixingConfig, setMixingConfig] = useState<MixingConfig>({
    enableMicrophone: true,
    enableDesktop: true,
    microphoneGain: 0.7,
    desktopGain: 0.8
  })
  const [audioLevels, setAudioLevels] = useState<AudioLevels>({
    microphoneLevel: 0,
    desktopLevel: 0,
    mixedLevel: 0
  })
  
  // Refs
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioMixingServiceRef = useRef<AudioMixingService | null>(null)
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null)
  const recordingStartTimeRef = useRef<number>(0)
  const pausedTimeRef = useRef<number>(0) // ä¸€æ™‚åœæ­¢æ™‚é–“ã®ç´¯è¨ˆ
  const micMonitorRef = useRef<MicrophoneMonitor | null>(null)
  // const realtimeProcessingIntervalRef = useRef<number | null>(null)
  const realtimeProcessingIntervalRef = useRef<number | null>(null); 
  const trueDiffGeneratorRef = useRef<TrueDifferentialChunkGenerator | null>(null)
  const realtimeProcessorRef = useRef<FileBasedRealtimeProcessor | null>(null)
  
  // HTMLAudioElementã‚’ä½¿ã£ã¦æ­£ç¢ºãªdurationã‚’å–å¾—ã™ã‚‹é–¢æ•°
  const getAccurateDuration = (blob: Blob): Promise<number> => {
    return new Promise((resolve, reject) => {
      const audio = new Audio()
      const url = URL.createObjectURL(blob)
      
      const cleanup = () => {
        URL.revokeObjectURL(url)
        audio.remove()
      }

      audio.src = url
      audio.addEventListener('loadedmetadata', () => {
        const duration = audio.duration
        if (isFinite(duration)) {
          cleanup()
          resolve(duration)
        } else {
          // durationãŒInfinityã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
          audio.currentTime = 1e101 // æœ«å°¾ã«ã‚·ãƒ¼ã‚¯ã—ã¦å¼·åˆ¶çš„ã«èª­ã¿è¾¼ã¾ã›ã‚‹
          const onTimeUpdate = () => {
            audio.removeEventListener('timeupdate', onTimeUpdate)
            cleanup()
            resolve(audio.duration)
          }
          audio.addEventListener('timeupdate', onTimeUpdate)
        }
      })
      audio.onerror = (e) => {
        cleanup()
        reject(new Error('éŸ³å£°ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ'))
      }
    })
  }
  
  // ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã‚’å–å¾—
  useEffect(() => {
    const getDevices = async () => {
      try {
        const devices = await navigator.mediaDevices.enumerateDevices()
        const audioInputs = devices.filter(device => device.kind === 'audioinput')
        setAvailableDevices(audioInputs)
        
        // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ãƒ»ä»®æƒ³éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ã‚’åˆ†é›¢ã—ã¦å–å¾—
        const systemDevices = audioInputs.filter(device => 
          device.label.toLowerCase().includes('stereo mix') ||
          device.label.toLowerCase().includes('what you hear') ||
          device.label.toLowerCase().includes('system audio') ||
          device.label.toLowerCase().includes('ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹') ||
          device.label.toLowerCase().includes('voicemeeter') ||
          device.label.toLowerCase().includes('virtual audio') ||
          device.label.toLowerCase().includes('vac') ||
          device.label.toLowerCase().includes('virtual cable')
        )
        setSystemAudioDevices(systemDevices)
        
        console.log('ğŸµ æ¤œå‡ºã•ã‚ŒãŸä»®æƒ³éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹:', systemDevices.map(d => d.label))
        
        if (audioInputs.length > 0 && !selectedDevice) {
          setSelectedDevice(audioInputs[0].deviceId)
        }
        
        if (systemDevices.length > 0 && !selectedSystemDevice) {
          setSelectedSystemDevice(systemDevices[0].deviceId)
        }
      } catch (error) {
        console.error('ãƒ‡ãƒã‚¤ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼:', error)
      }
    }
    getDevices()
  }, [selectedDevice, selectedSystemDevice])
  
  // ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚½ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—
  useEffect(() => {
    if (inputType === 'desktop' || inputType === 'mixing') {
      const getDesktopSources = async () => {
        try {
          const sources = await window.electronAPI.getDesktopSources()
          setDesktopSources(sources)
          
          // Step 7: ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚½ãƒ¼ã‚¹è©³ç´°ãƒ­ã‚°ã¨æ”¹å–„ã•ã‚ŒãŸé¸æŠãƒ­ã‚¸ãƒƒã‚¯
          console.log('ğŸ” ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚½ãƒ¼ã‚¹è©³ç´°åˆ†æ:');
          sources.forEach((source, index) => {
            console.log(`  ${index}: ID="${source.id}", Name="${source.name}"`);
          });
          
          // ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚½ãƒ¼ã‚¹å„ªå…ˆé¸æŠï¼ˆscreen: ã§å§‹ã¾ã‚‹ã‚‚ã®ï¼‰
          const screenSources = sources.filter(source => source.id.startsWith('screen:'));
          console.log('ğŸ–¥ï¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚½ãƒ¼ã‚¹å€™è£œ:', screenSources.map(s => ({ id: s.id, name: s.name })));
          
          // æœ€å„ªå…ˆ: ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚’ç‰¹å®šï¼ˆè‹±èªãƒ»æ—¥æœ¬èªä¸¡å¯¾å¿œï¼‰
          let selectedSource = screenSources.find(source => {
            const name = source.name.toLowerCase();
            return name.includes('entire screen') || 
                   name.includes('å…¨ç”»é¢');
          });
          
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ—ãƒ©ã‚¤ãƒãƒªãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚’é¸æŠï¼ˆé€šå¸¸ã¯screen:0:0ï¼‰
          if (!selectedSource) {
            selectedSource = screenSources.find(source => source.id === 'screen:0:0');
          }
          
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä»»æ„ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚½ãƒ¼ã‚¹
          if (!selectedSource && screenSources.length > 0) {
            selectedSource = screenSources[0];
          }
          
          // æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Screenåã‚„ç”»é¢åã‚’å«ã‚€ã‚½ãƒ¼ã‚¹ï¼ˆæ—¥æœ¬èªãƒ»è‹±èªä¸¡å¯¾å¿œï¼‰
          if (!selectedSource) {
            selectedSource = sources.find(source => {
              const name = source.name.toLowerCase();
              return (name.includes('screen') || source.name.includes('ç”»é¢')) && 
                     !source.id.startsWith('window:');
            });
          }
          
          if (selectedSource && selectedSource.id !== selectedDesktopSource) {
            console.log('âœ… é¸æŠã•ã‚ŒãŸãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚½ãƒ¼ã‚¹:', selectedSource);
            setSelectedDesktopSource(selectedSource.id);
          } else if (!selectedSource) {
            console.warn('âš ï¸ é©åˆ‡ãªã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
            console.warn('åˆ©ç”¨å¯èƒ½ãªã‚½ãƒ¼ã‚¹:', sources.map(s => s.name));
          }
        } catch (error) {
          console.error('ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚½ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼:', error)
        }
      }
      getDesktopSources()
    }
  }, [inputType]) // selectedDesktopSourceã‚’ä¾å­˜ã‹ã‚‰é™¤å»ã—ã¦ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’é˜²ã
  
  
  // éŒ²éŸ³æ™‚é–“ã‚’æ›´æ–°ï¼ˆdisplay:noneã§ã‚‚å‹•ä½œã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ï¼‰
  useEffect(() => {
    if (isRecording && !isPaused) {
      recordingTimerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)
    } else {
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current)
        recordingTimerRef.current = null
      }
    }
    
    return () => {
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current)
        recordingTimerRef.current = null
      }
    }
  }, [isRecording, isPaused])
  
  // æ™‚é–“ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
  const formatTime = useCallback((seconds: number): string => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }, [])

  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆæ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  // å…¥åŠ›ã‚¿ã‚¤ãƒ—ãŒå¤‰æ›´ã•ã‚ŒãŸéš›ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    // å…¥åŠ›ã‚¿ã‚¤ãƒ—ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€æ—¢å­˜ã®ãƒã‚¤ã‚¯ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’åœæ­¢
    if (inputType !== 'microphone' && micMonitorRef.current) {
      console.log('ğŸ¤ å…¥åŠ›ã‚¿ã‚¤ãƒ—å¤‰æ›´ã«ã‚ˆã‚Šãƒã‚¤ã‚¯ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’åœæ­¢:', inputType)
      try {
        micMonitorRef.current.stopMonitoring()
        micMonitorRef.current = null
        setMicStatus(null)
        setMicAlerts([])
      } catch (error) {
        console.error('ãƒã‚¤ã‚¯ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°åœæ­¢ã‚¨ãƒ©ãƒ¼:', error)
      }
    }
  }, [inputType])

  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆæ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      // ãƒã‚¤ã‚¯ç›£è¦–ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      if (micMonitorRef.current) {
        micMonitorRef.current.cleanup()
        micMonitorRef.current = null
      }
      
    }
  }, [])

  
  // éŒ²éŸ³é–‹å§‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
  const handleStartRecordingWithTranscription = useCallback(async () => {
    await startRecording(true);
  }, [inputType, selectedDevice, selectedDesktopSource, selectedSystemDevice]);

  const handleStartRecordingOnly = useCallback(async () => {
    await startRecording(false);
  }, [inputType, selectedDevice, selectedDesktopSource, selectedSystemDevice]);

  // éŒ²éŸ³çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆå…±é€šé–¢æ•°
  const resetRecordingState = useCallback(() => {
    setIsRecording(false)
    setGlobalIsRecording(false)
    setIsPaused(false)
    setRecordingTime(0)
  }, [setGlobalIsRecording]);

  // éŒ²éŸ³å‡¦ç†ã®å…±é€šé–¢æ•°
  const startRecording = useCallback(async (enableTranscription: boolean) => {
    console.log(`ğŸš¨ğŸš¨ğŸš¨ startRecordingé–¢æ•°é–‹å§‹ - enableTranscription=${enableTranscription} ğŸš¨ğŸš¨ğŸš¨`)
    try {
      let stream: MediaStream
      
      if (inputType === 'mixing') {
        // ãƒŸã‚­ã‚·ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
        console.log('ğŸ›ï¸ ãƒŸã‚­ã‚·ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰éŒ²éŸ³é–‹å§‹', mixingConfig);
        
        if (!audioMixingServiceRef.current) {
          audioMixingServiceRef.current = new AudioMixingService();
        }
        
        // éŸ³å£°ãƒ¬ãƒ™ãƒ«æ›´æ–°ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
        audioMixingServiceRef.current.setLevelsUpdateCallback((levels: AudioLevels) => {
          setAudioLevels(levels);
        });
        
        // ãƒŸã‚­ã‚·ãƒ³ã‚°è¨­å®šæ›´æ–°
        const config: MixingConfig = {
          ...mixingConfig,
          microphoneDeviceId: selectedDevice || undefined,
          desktopSourceId: selectedDesktopSource || undefined
        };
        
        // ãƒŸã‚­ã‚·ãƒ³ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆ
        stream = await audioMixingServiceRef.current.createMixedStream(config);
        console.log('âœ… ãƒŸã‚­ã‚·ãƒ³ã‚°ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆå®Œäº†');
      } else if (inputType === 'desktop') {
        if (!selectedDesktopSource) {
          throw new Error('ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚½ãƒ¼ã‚¹ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“');
        }
        
        try {
          console.log('ğŸ¬ Windowsãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°éŒ²éŸ³é–‹å§‹ï¼ˆgetDisplayMediaä½¿ç”¨ï¼‰');
          
          // æœ€å„ªå…ˆ: getDisplayMedia API + WASAPIãƒ­ãƒ¼ãƒ—ãƒãƒƒã‚¯
          console.log('ğŸ†• getDisplayMedia APIè©¦è¡Œï¼ˆWindows WASAPIãƒ­ãƒ¼ãƒ—ãƒãƒƒã‚¯å¯¾å¿œï¼‰');
          
          try {
            // @ts-ignore
            stream = await navigator.mediaDevices.getDisplayMedia({
              audio: true,
              video: {
                width: { ideal: 1 },
                height: { ideal: 1 }
              }
            });
            
            console.log('âœ… getDisplayMediaæˆåŠŸ - Windows WASAPIãƒ­ãƒ¼ãƒ—ãƒãƒƒã‚¯ä½¿ç”¨');
            
            // å–å¾—çµæœã®è©³ç´°ãƒ­ã‚°
            console.log('ğŸ” getDisplayMediaçµæœè©³ç´°:');
            console.log('  éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯æ•°:', stream.getAudioTracks().length);
            console.log('  æ˜ åƒãƒˆãƒ©ãƒƒã‚¯æ•°:', stream.getVideoTracks().length);
            
            const audioTracks = stream.getAudioTracks();
            if (audioTracks.length > 0) {
              const audioTrack = audioTracks[0];
              console.log('ğŸµ getDisplayMediaéŸ³å£°ãƒˆãƒ©ãƒƒã‚¯:', {
                label: audioTrack.label,
                id: audioTrack.id,
                kind: audioTrack.kind,
                enabled: audioTrack.enabled,
                readyState: audioTrack.readyState,
                settings: audioTrack.getSettings()
              });
            }
            
            // MediaRecorderå¯¾å¿œãƒã‚§ãƒƒã‚¯
            console.log('ğŸ” MediaRecorderå¯¾å¿œãƒã‚§ãƒƒã‚¯:');
            console.log('  - ã‚¹ãƒˆãƒªãƒ¼ãƒ æœ‰åŠ¹:', !!stream);
            console.log('  - éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯æ•°:', stream.getAudioTracks().length);
            console.log('  - æ˜ åƒãƒˆãƒ©ãƒƒã‚¯æ•°:', stream.getVideoTracks().length);
            
            // ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹MIMEã‚¿ã‚¤ãƒ—ã‚’ãƒã‚§ãƒƒã‚¯
            const supportedTypes = [
              'audio/webm',
              'audio/webm;codecs=opus',
              'audio/webm;codecs=vorbis',
              'video/webm',
              'video/webm;codecs=vp8',
              'video/webm;codecs=vp9'
            ];
            
            console.log('ğŸ” ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹MIMEã‚¿ã‚¤ãƒ—:');
            supportedTypes.forEach(type => {
              const isSupported = MediaRecorder.isTypeSupported(type);
              console.log(`  - ${type}: ${isSupported}`);
            });
            
            // æ˜ åƒãƒˆãƒ©ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯å‰Šé™¤ã—ã¦éŸ³å£°ã®ã¿ã«ã™ã‚‹
            const videoTracks = stream.getVideoTracks();
            if (videoTracks.length > 0) {
              console.log('ğŸ¥ æ˜ åƒãƒˆãƒ©ãƒƒã‚¯ã‚’åœæ­¢ã—ã¦éŸ³å£°ã®ã¿ã«å¤‰æ›´');
              videoTracks.forEach(track => {
                track.stop();
                stream.removeTrack(track);
              });
              console.log('âœ… æ˜ åƒãƒˆãƒ©ãƒƒã‚¯å‰Šé™¤å®Œäº†ã€éŸ³å£°ã®ã¿ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆ');
            }
            
          } catch (getDisplayMediaError) {
            console.warn('âŒ getDisplayMediaå¤±æ•—ã€å¾“æ¥æ–¹å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:', getDisplayMediaError);
            
            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®getUserMediaæ–¹å¼
            const availableScreenSources = desktopSources.filter(s => s.id.startsWith('screen:'));
            if (availableScreenSources.length === 0) {
              throw new Error('ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
            }
            
            const forcedSource = availableScreenSources[0];
            console.log('ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: getUserMediaä½¿ç”¨', forcedSource.id);
            
            stream = await navigator.mediaDevices.getUserMedia({
              audio: {
                chromeMediaSource: 'desktop',
                chromeMediaSourceId: forcedSource.id,
                echoCancellation: false,
                noiseSuppression: false,
                autoGainControl: false
              } as any,
              video: false
            });
            console.log('âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ');
          }
          
          // éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã‚’ãƒã‚§ãƒƒã‚¯
          const audioTracks = stream.getAudioTracks();
          console.log(`ğŸµ éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯æ•°: ${audioTracks.length}`);
          
          if (audioTracks.length === 0) {
            throw new Error('ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‹ã‚‰ã®éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ');
          }
          
          // éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
          audioTracks.forEach((track, index) => {
            console.log(`ğŸ¤ éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯${index}:`, {
              id: track.id,
              label: track.label,
              enabled: track.enabled,
              muted: track.muted,
              readyState: track.readyState
            });
          });

          // Step 6: éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã®æ­£å½“æ€§ãƒã‚§ãƒƒã‚¯å¼·åŒ–
          const firstTrack = audioTracks[0];
          console.log('ğŸ” éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯æ¤œè¨¼:');
          console.log('  - ãƒ©ãƒ™ãƒ«:', firstTrack.label);
          console.log('  - ID:', firstTrack.id);

          // Step 17: éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯æ¤œè¨¼ã‚’å¾©æ´»ã•ã›ã¦å•é¡Œã‚’ç‰¹å®š
          const trackLabel = firstTrack.label.toLowerCase();
          const isMicrophoneTrack = trackLabel.includes('microphone') ||
                                  trackLabel.includes('mic') ||
                                  trackLabel.includes('hyperx') ||
                                  trackLabel.includes('headset');
          
          if (isMicrophoneTrack) {
            console.error('âŒ ãƒã‚¤ã‚¯ãƒˆãƒ©ãƒƒã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:', firstTrack.label);
            console.error('âŒ é¸æŠã•ã‚ŒãŸã‚½ãƒ¼ã‚¹:', selectedDesktopSource);
            console.error('ğŸ”„ ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹æ–¹å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸­...');
            
            // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
            stream.getTracks().forEach(track => track.stop());
            
            // ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹æ–¹å¼ã‚’è©¦è¡Œ
            try {
              const audioDevices = await navigator.mediaDevices.enumerateDevices();
              const stereoMixDevice = audioDevices.find(device => 
                device.kind === 'audioinput' && 
                (device.label.toLowerCase().includes('stereo mix') ||
                 device.label.toLowerCase().includes('ã‚¹ãƒ†ãƒ¬ã‚ª ãƒŸãƒƒã‚¯ã‚¹') ||
                 device.label.toLowerCase().includes('what u hear') ||
                 device.label.toLowerCase().includes('loopback'))
              );
              
              if (stereoMixDevice) {
                console.log('ğŸµ ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹ãƒ‡ãƒã‚¤ã‚¹ç™ºè¦‹:', stereoMixDevice.label);
                stream = await navigator.mediaDevices.getUserMedia({
                  audio: {
                    deviceId: stereoMixDevice.deviceId,
                    echoCancellation: false,
                    noiseSuppression: false,
                    autoGainControl: false
                  }
                });
                console.log('âœ… ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹ã§ã®éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£æˆåŠŸ');
                
                // æ–°ã—ã„ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã‚’ãƒã‚§ãƒƒã‚¯
                const newAudioTracks = stream.getAudioTracks();
                if (newAudioTracks.length > 0) {
                  console.log('ğŸµ ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯:', newAudioTracks[0].label);
                }
              } else {
                throw new Error('ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
              }
            } catch (stereoMixError) {
              console.error('âŒ ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹ã‚‚å¤±æ•—:', stereoMixError);
              
              // æœ€çµ‚çš„ãªè§£æ±ºæ–¹æ³•ã‚’æç¤º
              console.log('ğŸ’¡ Windowsç’°å¢ƒã§ã®ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°éŒ²éŸ³æ–¹æ³•:');
              console.log('1. Voicemeeter Bananaã‚’ä½¿ç”¨ (æ¤œå‡ºæ¸ˆã¿)');
              console.log('2. Virtual Audio Cable (VAC)');
              console.log('3. OBS Virtual Audio Filter');
              console.log('4. Windowsè¨­å®šã§ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹ã‚’æœ‰åŠ¹åŒ–');
              
              throw new Error(
                `Windowsç’°å¢ƒã§ã®ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£åˆ¶é™\n\n` +
                `è§£æ±ºæ–¹æ³•:\n` +
                `1. Voicemeeter Banana (æ¨å¥¨)\n` +
                `   - æ—¢ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã§ã™\n` +
                `   - A1: ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼\n` +
                `   - B1: Virtual Input (éŒ²éŸ³ç”¨)\n` +
                `   - ã‚¢ãƒ—ãƒªã§B1ã‚’é¸æŠ\n\n` +
                `2. Windowsè¨­å®š > ã‚µã‚¦ãƒ³ãƒ‰ > éŒ²éŸ³\n` +
                `   - ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹æœ‰åŠ¹åŒ–\n` +
                `   - æ—¢å®šã®ãƒ‡ãƒã‚¤ã‚¹ã«è¨­å®š\n\n` +
                `3. ãƒã‚¤ã‚¯å…¥åŠ›ã‚¿ã‚¤ãƒ—ã«å¤‰æ›´ã—ã¦\n` +
                `   ä»®æƒ³éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ã‚’é¸æŠ\n\n` +
                `ç¾åœ¨ã®æŠ€è¡“çš„åˆ¶ç´„ã«ã‚ˆã‚Šã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°ã®\n` +
                `ç›´æ¥ã‚­ãƒ£ãƒ—ãƒãƒ£ãŒã§ãã¾ã›ã‚“ã€‚`
              );
            }
          }
          
          console.log('âœ… éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯æ¤œè¨¼å®Œäº†: ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°ã¨åˆ¤å®š');
          
          console.log('âœ… éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ å–å¾—å®Œäº†');
          
        } catch (desktopError) {
          console.error('âŒ Desktop capturer failed:', desktopError);
          console.error('âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°:', {
            name: desktopError instanceof Error ? desktopError.name : 'Unknown',
            message: desktopError instanceof Error ? desktopError.message : String(desktopError),
            selectedDesktopSource,
            availableSources: desktopSources.length
          });
          throw new Error(`ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã«å¤±æ•—ã—ã¾ã—ãŸ: ${desktopError instanceof Error ? desktopError.message : String(desktopError)}`);
        }
        
      } else if (inputType === 'stereo-mix') {
        if (!selectedSystemDevice) {
          throw new Error('ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“');
        }
        
        stream = await navigator.mediaDevices.getUserMedia({
          audio: { 
            deviceId: selectedSystemDevice,
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false
          }
        });
        
      } else {
        // ãƒã‚¤ã‚¯éŸ³å£°
        stream = await navigator.mediaDevices.getUserMedia({
          audio: { deviceId: selectedDevice }
        })
      }
      
      // MediaRecorderè¨­å®š
      console.log('ğŸ¬ MediaRecorderåˆæœŸåŒ–é–‹å§‹');
      console.log('  - ã‚¹ãƒˆãƒªãƒ¼ãƒ çŠ¶æ…‹:', {
        active: stream.active,
        audioTracks: stream.getAudioTracks().length,
        videoTracks: stream.getVideoTracks().length
      });
      
      let mediaRecorder: MediaRecorder
      let selectedMimeType: string
      
      const recorderOptions: MediaRecorderOptions = {
        audioBitsPerSecond: 128000
      };
      
      try {
        if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
          selectedMimeType = 'audio/webm;codecs=opus'
          recorderOptions.mimeType = selectedMimeType
          console.log('ğŸµ MediaRecorderåˆæœŸåŒ–:', selectedMimeType);
          mediaRecorder = new MediaRecorder(stream, recorderOptions)
        } else if (MediaRecorder.isTypeSupported('audio/webm')) {
          selectedMimeType = 'audio/webm'
          recorderOptions.mimeType = selectedMimeType
          console.log('ğŸµ MediaRecorderåˆæœŸåŒ–:', selectedMimeType);
          mediaRecorder = new MediaRecorder(stream, recorderOptions)
        } else {
          console.log('ğŸµ MediaRecorderåˆæœŸåŒ–: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³');
          mediaRecorder = new MediaRecorder(stream, recorderOptions)
          selectedMimeType = mediaRecorder.mimeType
        }
        
        console.log('âœ… MediaRecorderä½œæˆæˆåŠŸ:', {
          mimeType: selectedMimeType,
          state: mediaRecorder.state,
          audioBitsPerSecond: recorderOptions.audioBitsPerSecond
        });
        
      } catch (mediaRecorderError) {
        console.error('âŒ MediaRecorderä½œæˆã‚¨ãƒ©ãƒ¼:', mediaRecorderError);
        
        // ã‚ˆã‚Šå®‰å…¨ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å†è©¦è¡Œ
        console.log('ğŸ”„ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§MediaRecorderå†è©¦è¡Œ');
        try {
          mediaRecorder = new MediaRecorder(stream);
          selectedMimeType = mediaRecorder.mimeType;
          console.log('âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§MediaRecorderä½œæˆæˆåŠŸ:', selectedMimeType);
        } catch (fallbackError) {
          console.error('âŒ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã‚‚å¤±æ•—:', fallbackError);
          throw new Error(`MediaRecorderã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: ${fallbackError instanceof Error ? fallbackError.message : String(fallbackError)}`);
        }
      }
      
      mediaRecorderRef.current = mediaRecorder

      // MediaRecorderã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼
      mediaRecorder.onerror = (event) => {
        console.error('MediaRecorderã‚¨ãƒ©ãƒ¼:', event.error)
        try {
          if (mediaRecorder.state === 'recording') {
            mediaRecorder.stop()
          }
          stream.getTracks().forEach(track => track.stop())
        } catch (cleanupError) {
          console.error('ã‚¨ãƒ©ãƒ¼æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—:', cleanupError)
        }
        
        // TrueDifferentialChunkGeneratorã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if (trueDiffGeneratorRef.current) {
          trueDiffGeneratorRef.current.cleanup()
        }
      }
      
      // å·®åˆ†ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒç”¨ã®å¤‰æ•°
      let recordingFilePath: string | null = null
      let recordingFilename: string | null = null
      let tempFolderPath: string | null = null
      
      // ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚å¸¸ã«æœ‰åŠ¹åŒ–
      tempFolderPath = 'chunks' // ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç”¨ã®subfolderæŒ‡å®š
      console.log(`ğŸ”§ ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆæœ‰åŠ¹ - ä¿å­˜å…ˆ: ${tempFolderPath}`)
      
      // ãƒ†ã‚¹ãƒˆç”¨: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’å¼·åˆ¶çš„ã«æœ‰åŠ¹åŒ–
      console.log(`ğŸ§ª ãƒ†ã‚¹ãƒˆç”¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—å¼·åˆ¶æœ‰åŠ¹åŒ–: ${FORCE_ENABLE_REALTIME_TRANSCRIPTION}`)
      
      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ç”¨ã®è¿½åŠ è¨­å®š
      if (enableTranscription || FORCE_ENABLE_REALTIME_TRANSCRIPTION) {
        console.log(`ğŸ“ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚‚æœ‰åŠ¹ - FileBasedRealtimeProcessorã‚’åˆæœŸåŒ–`)
        
        // FileBasedRealtimeProcessorã‚’åˆæœŸåŒ–
        if (!realtimeProcessorRef.current) {
          realtimeProcessorRef.current = new FileBasedRealtimeProcessor({
            fileCheckInterval: 2000, // 2ç§’é–“éš”ã§ãƒã‚§ãƒƒã‚¯
            maxRetryCount: 2,
            processingTimeout: 180000,
            enableAutoRetry: true,
            textWriteInterval: 5000,
            enableAutoSave: true,
            textFormat: 'detailed'
          })
          
          console.log(`ğŸ¯ FileBasedRealtimeProcessoråˆæœŸåŒ–å®Œäº†`)
        }
      }
      
      // TrueDifferentialChunkGeneratorã‚’åˆæœŸåŒ–ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æ©Ÿèƒ½ä»˜ãï¼‰
      if (!trueDiffGeneratorRef.current) {
        trueDiffGeneratorRef.current = new TrueDifferentialChunkGenerator(20, {
          intervalSeconds: 20,
          enableFileGeneration: !!tempFolderPath, // tempFolderPathãŒã‚ã‚‹å ´åˆã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æœ‰åŠ¹
          tempFolderPath: tempFolderPath || undefined,
          enableAutoGeneration: true // è‡ªå‹•ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´
        })
        
        // ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
        trueDiffGeneratorRef.current.onChunkGenerated((result) => {
          console.log(`âœ… ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆå®Œäº†: #${result.chunkNumber}, ${result.dataSize}bytes, ${result.duration.toFixed(1)}s`)
          if (result.filePath) {
            console.log(`ğŸ’¾ ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: ${result.filePath}`)
          }
        })
        
        trueDiffGeneratorRef.current.onChunkSaved((fileInfo) => {
          console.log(`ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: ${fileInfo.filename} (${fileInfo.sizeBytes}bytes)`)
          
          // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ãŒæœ‰åŠ¹ãªå ´åˆã€FileBasedRealtimeProcessorã«é€šçŸ¥
          if ((enableTranscription || FORCE_ENABLE_REALTIME_TRANSCRIPTION) && realtimeProcessorRef.current) {
            console.log(`ğŸ”— FileBasedRealtimeProcessorã«ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–é–‹å§‹ã‚’é€šçŸ¥: ${fileInfo.filepath}`)
            // ã“ã“ã§ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚’é–‹å§‹ã™ã‚‹çµ±åˆå‡¦ç†ã‚’å¾Œã§å®Ÿè£…
          }
        })
        
        trueDiffGeneratorRef.current.onError((error) => {
          console.error(`âŒ ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼:`, error)
        })
      } else {
        // æ—¢å­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è¨­å®šæ›´æ–°
        trueDiffGeneratorRef.current.updateConfig({
          intervalSeconds: 20,
          enableFileGeneration: !!tempFolderPath,
          tempFolderPath: tempFolderPath || undefined,
          enableAutoGeneration: true
        })
        trueDiffGeneratorRef.current.reset()
      }
      
      // éŒ²éŸ³é–‹å§‹
      trueDiffGeneratorRef.current.startRecording()
      
      // éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’TrueDifferentialChunkGeneratorã«è¿½åŠ 
      mediaRecorder.ondataavailable = (event: BlobEvent) => {
        if (event.data.size > 0 && trueDiffGeneratorRef.current) {
          const currentTime = trueDiffGeneratorRef.current.getCurrentRecordingTime()
          trueDiffGeneratorRef.current.addRecordingData(event.data)
          console.log(`ğŸ“ ãƒãƒ£ãƒ³ã‚¯å—ä¿¡: ${event.data.size} bytes (éŒ²éŸ³æ™‚é–“: ${currentTime.toFixed(1)}s)`)
          console.log(`ğŸ“Š ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡:`, trueDiffGeneratorRef.current.getMemoryUsage())
          
        }
      }
        
      mediaRecorder.onstop = async () => {
        // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã®ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
        if (realtimeProcessingIntervalRef.current) {
          window.clearInterval(realtimeProcessingIntervalRef.current)
          realtimeProcessingIntervalRef.current = null
        }
        
        // æ­£ç¢ºãªéŒ²éŸ³æ™‚é–“ã‚’è¨ˆç®—ï¼ˆãƒŸãƒªç§’å˜ä½ã€ä¸€æ™‚åœæ­¢æ™‚é–“ã‚’é™¤å¤–ï¼‰
        const recordingEndTime = Date.now()
        const actualDurationMs = recordingEndTime - recordingStartTimeRef.current - pausedTimeRef.current
        const actualDurationSeconds = Math.round(actualDurationMs / 1000)
        
        // WebMå½¢å¼ã§Blobã‚’ä½œæˆ
        let originalBlob: Blob
        
        // éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        if (trueDiffGeneratorRef.current) {
          const memoryUsage = trueDiffGeneratorRef.current.getMemoryUsage()
          console.log(`ğŸ“ æœ€çµ‚éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: ${memoryUsage.totalBytes} bytes (${memoryUsage.chunkCount}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ä½œæˆ)`)
          originalBlob = new Blob(trueDiffGeneratorRef.current.getAllChunks(), { type: selectedMimeType })
        } else {
          console.warn('âš ï¸ ã‚·ã‚¹ãƒ†ãƒ æœªåˆæœŸåŒ– - ç©ºã®Blobã‚’ä½œæˆ')
          originalBlob = new Blob([], { type: selectedMimeType })
        }
        
        try {
          // HTMLAudioElementã§æ­£ç¢ºãªdurationã‚’å–å¾—
          let accurateDuration: number
          
          try {
            accurateDuration = await getAccurateDuration(originalBlob)
          } catch (durationError) {
            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šéŒ²éŸ³æ™‚é–“ã‹ã‚‰æ¨å®šdurationã‚’è¨ˆç®—
            accurateDuration = actualDurationSeconds
          }
          
          // å…ƒã®WebMãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾ä½¿ç”¨
          const finalBuffer = await originalBlob.arrayBuffer()
          
          // éŒ²éŸ³åœæ­¢æ™‚ã¯å¿…ãšæ–°ã—ã„å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
          // éŒ²éŸ³é–‹å§‹æ™‚ã«æ±ºå®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨ï¼ˆä¸€è²«æ€§ã‚’ä¿ã¤ï¼‰
          const filename = recordingFilename || 'recording.webm'
          console.log('éŒ²éŸ³é–‹å§‹æ™‚ã«æ±ºå®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã§æœ€çµ‚ä¿å­˜:', filename)
          
          console.log('Saving WebM file with duration metadata:', filename)
          
          try {
            // æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ï¼ˆéŒ²éŸ³ä¸­ã«æ›¸ãè¾¼ã‚“ã ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Œå…¨ç‰ˆã§ä¸Šæ›¸ãï¼‰
            console.log('éŒ²éŸ³åœæ­¢æ™‚ã®æœ€çµ‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜:', {
              filename: filename,
              bufferSize: finalBuffer.byteLength,
              duration: accurateDuration,
              recordingPath: recordingFilePath
            })
            
            await window.electronAPI.saveFile(finalBuffer, filename)
            
            // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã«æ­£ç¢ºãªdurationã‚’ä¿å­˜
            const metadata = {
              duration: accurateDuration, // HTMLAudioElementã§å–å¾—ã—ãŸæ­£ç¢ºãªå€¤
              format: 'webm',
              size: finalBuffer.byteLength,
              recordedAt: new Date().toISOString(),
              mimeType: selectedMimeType
            }
            await window.electronAPI.saveMetadata(filename, metadata)
            
            console.log('ğŸ“ éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ:', filename)
            console.log('â±ï¸ Accurate Duration:', accurateDuration, 'seconds')
            console.log('ğŸ“‹ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜ã—ã¾ã—ãŸ')
            console.log('âœ… WebMãƒ•ã‚¡ã‚¤ãƒ«ã¨æ­£ç¢ºãªdurationãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†')
          } catch (error) {
            console.error('ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼:', error)
          }
          
        } catch (durationError) {
          console.error('Durationå–å¾—ã‚¨ãƒ©ãƒ¼:', durationError)
          console.log('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®WebMãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã™ï¼ˆDurationæƒ…å ±ãªã—ï¼‰')
          
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
          const fallbackBuffer = await originalBlob.arrayBuffer()
          
          const now = new Date()
          const timestamp = `${now.getFullYear()}${(now.getMonth() + 1).toString().padStart(2, '0')}${now.getDate().toString().padStart(2, '0')}_${now.getHours().toString().padStart(2, '0')}${now.getMinutes().toString().padStart(2, '0')}${now.getSeconds().toString().padStart(2, '0')}`
          const filename = `recording_${timestamp}.webm`
          
          try {
            await window.electronAPI.saveFile(fallbackBuffer, filename)
            console.log('âš ï¸ éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆDurationç„¡ã—ï¼‰:', filename)
          } catch (error) {
            console.error('ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼:', error)
          }
        }
        
        // éŒ²éŸ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        resetRecordingState()
        
        // éŒ²éŸ³å®Œäº†å¾Œã«recordingFileã‚’ã‚¯ãƒªã‚¢ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆæ›´æ–°ã¯ LeftPanel ã«ä»»ã›ã‚‹ï¼‰
        const cleanupRecordingState = () => {
          setRecordingFile(null)
          console.log('ğŸ¯ éŒ²éŸ³ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢')
        }
        
        // å°‘ã—é…å»¶ã‚’å…¥ã‚Œã¦ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
        setTimeout(cleanupRecordingState, 500)
      }
      
      // éŒ²éŸ³é–‹å§‹æ™‚ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªã‚’å³åº§ã«ä½œæˆï¼ˆå·¦ãƒšã‚¤ãƒ³ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ï¼‰
      const createInitialFileEntry = async () => {
        try {
          const now = new Date()
          const timestamp = `${now.getFullYear()}${(now.getMonth() + 1).toString().padStart(2, '0')}${now.getDate().toString().padStart(2, '0')}_${now.getHours().toString().padStart(2, '0')}${now.getMinutes().toString().padStart(2, '0')}${now.getSeconds().toString().padStart(2, '0')}`
          const filename = `recording_${timestamp}.webm`
          
          // éŒ²éŸ³ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’åˆæœŸåŒ–ï¼ˆondataavailableã§ä½¿ç”¨ï¼‰
          recordingFilePath = null
          recordingFilename = filename  // ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…±æœ‰å¤‰æ•°ã«è¨­å®š
          
          // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—
          const settings = await window.electronAPI.loadSettings()
          const defaultFolder = settings.saveFolder
          
          // ä¸€æ™‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
          const tempFileEntry = {
            id: filename,
            filename: filename,
            filepath: `${defaultFolder}\\${filename}`,
            format: 'webm' as const,
            size: 0,
            createdAt: now,
            duration: 0,
            hasTranscriptionFile: false,
            transcriptionPath: undefined,
            isRecording: true // éŒ²éŸ³ä¸­ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
          }
          
          // æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã«éŒ²éŸ³ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
          // ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®å†å–å¾—ã‚’é¿ã‘ã¦ã€ç¾åœ¨ã®ãƒªã‚¹ãƒˆã«è¿½åŠ ã®ã¿è¡Œã†
          setFileList(prevList => {
            // åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«åãŒã™ã§ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ç½®ãæ›ãˆã€ãã†ã§ãªã‘ã‚Œã°å…ˆé ­ã«è¿½åŠ 
            const existingIndex = prevList.findIndex(file => file.filename === filename)
            if (existingIndex >= 0) {
              const newList = [...prevList]
              newList[existingIndex] = tempFileEntry
              return newList
            } else {
              return [tempFileEntry, ...prevList]
            }
          })
          
          // ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã«éŒ²éŸ³ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­å®š
          setRecordingFile(tempFileEntry)
          
          // éŒ²éŸ³ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•çš„ã«é¸æŠ
          setSelectedFile(tempFileEntry)
          
          console.log('ğŸ“ éŒ²éŸ³ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å·¦ãƒšã‚¤ãƒ³ã«è¿½åŠ :', filename)
          console.log('ğŸ¯ ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã«éŒ²éŸ³ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­å®š:', tempFileEntry.filename)
          console.log('ğŸ¯ éŒ²éŸ³ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•é¸æŠ:', tempFileEntry.filename)
          console.log('ğŸ¯ éŒ²éŸ³ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°:', {
            id: tempFileEntry.id,
            filename: tempFileEntry.filename,
            isRecording: tempFileEntry.isRecording,
            filepath: tempFileEntry.filepath
          })
          
          // ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æˆ»ã‚Šå€¤ã¨ã—ã¦è¿”ã™
          return { filename }
          
        } catch (error) {
          console.error('éŒ²éŸ³ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªä½œæˆã‚¨ãƒ©ãƒ¼:', error)
          throw error
        }
      }
      
      // createInitialFileEntry ã‚’å®Ÿè¡Œã—ã¦ã‹ã‚‰MediaRecorderã‚’é–‹å§‹
      const { filename } = await createInitialFileEntry()
      recordingFilename = filename // å…±æœ‰å¤‰æ•°ã«è¨­å®š
      
      // recordingFilenameãŒæ±ºã¾ã£ãŸã‚‰ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚©ãƒ«ãƒ€åã‚’æ›´æ–°
      const baseFilename = filename.replace('.webm', '') // æ‹¡å¼µå­ã‚’é™¤å»
      tempFolderPath = `${baseFilename}_chunks` // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«åãƒ™ãƒ¼ã‚¹ã®chunksãƒ•ã‚©ãƒ«ãƒ€
      console.log(`ğŸ“ ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚©ãƒ«ãƒ€æ›´æ–°: ${tempFolderPath}`)
      
      // TrueDifferentialChunkGeneratorã®è¨­å®šã‚’æ›´æ–°
      if (trueDiffGeneratorRef.current) {
        trueDiffGeneratorRef.current.updateConfig({
          enableFileGeneration: true,
          tempFolderPath: tempFolderPath
        })
        console.log(`ğŸ”§ TrueDifferentialChunkGeneratorè¨­å®šæ›´æ–°: ${tempFolderPath}`)
      }
      
      // FileBasedRealtimeProcessorã‚’é–‹å§‹ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—æœ‰åŠ¹æ™‚ï¼‰
      if ((enableTranscription || FORCE_ENABLE_REALTIME_TRANSCRIPTION) && realtimeProcessorRef.current && tempFolderPath && recordingFilename) {
        try {
          // Kotoba-Whisperã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ç¢ºèª
          const serverStatus = await window.electronAPI.speechGetServerStatus()
          console.log(`ğŸ” Kotoba-Whisperã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹:`, serverStatus)
          
          if (!serverStatus.isRunning) {
            console.log(`ğŸš€ Kotoba-Whisperã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­...`)
            const startResult = await window.electronAPI.speechStartServer()
            console.log(`ğŸš€ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•çµæœ:`, startResult)
            
            if (!startResult) {
              console.error(`âŒ Kotoba-Whisperã‚µãƒ¼ãƒãƒ¼èµ·å‹•å¤±æ•—`)
              throw new Error('æ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ')
            }
          }
          
          // å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®šï¼ˆéŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«åãƒ™ãƒ¼ã‚¹ï¼‰
          const settings = await window.electronAPI.loadSettings()
          const outputFilePath = `${settings.saveFolder}/${baseFilename}_realtime.txt`
          const watchFolderPath = `${settings.saveFolder}/${tempFolderPath}`
          
          console.log(`ğŸ¬ FileBasedRealtimeProcessoré–‹å§‹`)
          console.log(`ğŸ“‚ ç›£è¦–ãƒ•ã‚©ãƒ«ãƒ€: ${watchFolderPath}`)
          console.log(`ğŸ“„ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: ${outputFilePath}`)
          
          await realtimeProcessorRef.current.start(watchFolderPath, outputFilePath)
          console.log(`âœ… FileBasedRealtimeProcessoré–‹å§‹å®Œäº†`)
          
        } catch (error) {
          console.error(`âŒ FileBasedRealtimeProcessoré–‹å§‹ã‚¨ãƒ©ãƒ¼:`, error)
        }
      }
      
      // ãƒã‚¤ã‚¯ç›£è¦–ã‚’é–‹å§‹ï¼ˆãƒã‚¤ã‚¯éŒ²éŸ³ã®å ´åˆã®ã¿ï¼‰ - å®Œå…¨ã«ç„¡åŠ¹åŒ–ã—ã¦ã‚¯ãƒ©ãƒƒã‚·ãƒ¥å•é¡Œã‚’åˆ‡ã‚Šåˆ†ã‘
      const ENABLE_MIC_MONITORING = false // å®Œå…¨ã«ç„¡åŠ¹åŒ–
      
      if (inputType === 'microphone' && ENABLE_MIC_MONITORING) {
        try {
          console.log('ğŸ¤ ãƒã‚¤ã‚¯ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã™...')
          micMonitorRef.current = new MicrophoneMonitor()
          
          // ãƒã‚¤ã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
          micMonitorRef.current.onStatusUpdate((status: MicrophoneStatus) => {
            setMicStatus(status)
          })
          
          // ãƒã‚¤ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
          micMonitorRef.current.onAlert((alert: MicrophoneAlert) => {
            setMicAlerts(prev => [...prev.slice(-4), alert]) // æœ€æ–°5ä»¶ã¾ã§ä¿æŒ
            
            // é‡è¦ãªã‚¢ãƒ©ãƒ¼ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
            if (alert.severity === 'error' || alert.severity === 'warning') {
              console.warn(`ğŸ¤ ãƒã‚¤ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆ: ${alert.message}`)
              if (alert.recommendation) {
                console.warn(`   æ¨å¥¨å¯¾ç­–: ${alert.recommendation}`)
              }
            }
          })
          
          // éŒ²éŸ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ã‚¯ç›£è¦–é–‹å§‹ï¼ˆç«¶åˆã‚’å›é¿ï¼‰
          const micMonitoringStarted = await micMonitorRef.current.startMonitoring(stream, selectedDevice)
          if (micMonitoringStarted) {
            console.log('âœ… ãƒã‚¤ã‚¯ç›£è¦–é–‹å§‹æˆåŠŸï¼ˆéŒ²éŸ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½¿ç”¨ï¼‰')
          } else {
            console.warn('âš ï¸ ãƒã‚¤ã‚¯ç›£è¦–é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€éŒ²éŸ³ã¯ç¶šè¡Œã—ã¾ã™')
          }
        } catch (micError) {
          console.error('âŒ ãƒã‚¤ã‚¯ç›£è¦–é–‹å§‹ã‚¨ãƒ©ãƒ¼:', micError)
          console.warn('âš ï¸ ãƒã‚¤ã‚¯ç›£è¦–ãªã—ã§éŒ²éŸ³ã‚’ç¶šè¡Œã—ã¾ã™')
        }
      } else if (inputType === 'microphone') {
        console.log('ğŸ¤ ãƒã‚¤ã‚¯ç›£è¦–ã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼ˆéŒ²éŸ³ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ä¸­ï¼‰')
      }
      
      // æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼štimesliceãªã—ã§éŒ²éŸ³é–‹å§‹
      console.log('ğŸ¬ MediaRecorderé–‹å§‹ä¸­ï¼ˆtimesliceãªã—ï¼‰...', { state: mediaRecorder.state })
      console.log('ğŸ” é–‹å§‹å‰æœ€çµ‚ãƒã‚§ãƒƒã‚¯:', {
        streamActive: stream.active,
        audioTracks: stream.getAudioTracks().map(t => ({
          label: t.label,
          enabled: t.enabled,
          readyState: t.readyState
        })),
        recorderState: mediaRecorder.state,
        mimeType: selectedMimeType
      });
      
      // éŒ²éŸ³æº–å‚™å®Œäº†
      console.log('âœ… éŒ²éŸ³æº–å‚™å®Œäº†')

      console.log(`ğŸ¬ğŸ¬ğŸ¬ MediaRecorder.start()ã‚’å‘¼ã³å‡ºã—ç›´å‰ ğŸ¬ğŸ¬ğŸ¬`)
      
      try {
        mediaRecorder.start() // timesliceãªã—ã§é€£ç¶šéŒ²éŸ³ï¼ˆæ‰‹å‹•ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚’ä½¿ç”¨ï¼‰
        console.log('âœ… MediaRecorder.start()å‘¼ã³å‡ºã—å®Œäº†, æ–°ã—ã„state:', mediaRecorder.state)
        if (true) { // æ‰‹å‹•requestData()å‡¦ç†ã‚’æœ‰åŠ¹åŒ–
          console.log('ğŸ“ æ‰‹å‹•ãƒ‡ãƒ¼ã‚¿è¦æ±‚ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã™ (20ç§’é–“éš”)');
          
          const generator = trueDiffGeneratorRef.current!;
          const recorder = mediaRecorderRef.current!;
          
          // éåŒæœŸãƒ«ãƒ¼ãƒ—å‡¦ç†ã®å®šç¾©
          const processingLoop = async () => {
            try {
              // éŒ²éŸ³ãŒç¶™ç¶šã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
              if (recorder.state !== 'recording') {
                console.log('ğŸ“ éŒ²éŸ³ãŒåœæ­¢ã—ãŸãŸã‚ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ãƒ«ãƒ¼ãƒ—ã‚’çµ‚äº†ã—ã¾ã™ã€‚');
                return;
              }

              // 1. requestData()ã§æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¦æ±‚
              console.log('ğŸ“¡ requestData()ã§ãƒ‡ãƒ¼ã‚¿è¦æ±‚ä¸­...')
              recorder.requestData();
              
              // 2. ondataavailableãŒå®Ÿè¡Œã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ãŒã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã«è¿½åŠ ã•ã‚Œã‚‹ã®ã‚’å°‘ã—å¾…ã¤
              await new Promise(resolve => setTimeout(resolve, 500));
              
              console.log('ğŸ“¡ requestData()å®Œäº†ã€è‡ªå‹•ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆé–‹å§‹ã‚’ãƒˆãƒªã‚¬ãƒ¼')

            } catch (error) {
              console.error(`âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ãƒ«ãƒ¼ãƒ—å†…ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:`, error);
            } finally {
              // 4. æ¬¡ã®ãƒ«ãƒ¼ãƒ—ã‚’20ç§’å¾Œã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã™ã‚‹
              if (mediaRecorderRef.current?.state === 'recording') {
                realtimeProcessingIntervalRef.current = window.setTimeout(processingLoop, 20000);
              }
            }
          };

          // æœ€åˆã®ãƒ«ãƒ¼ãƒ—ã‚’20ç§’å¾Œã«é–‹å§‹
          realtimeProcessingIntervalRef.current = window.setTimeout(processingLoop, 20000);
        }
      } catch (startError) {
        console.error('âŒ MediaRecorder.start()ã‚¨ãƒ©ãƒ¼:', startError);
        console.error('âŒ ã‚¨ãƒ©ãƒ¼æ™‚ã®çŠ¶æ…‹:', {
          streamActive: stream.active,
          audioTracksCount: stream.getAudioTracks().length,
          recorderState: mediaRecorder.state,
          errorName: startError instanceof Error ? startError.name : 'Unknown',
          errorMessage: startError instanceof Error ? startError.message : String(startError)
        });
        throw new Error(`éŒ²éŸ³é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: ${startError instanceof Error ? startError.message : String(startError)}`);
      }
      setIsRecording(true)
      setGlobalIsRecording(true)
      setRecordingTime(0)
      console.log('ğŸ“± UIçŠ¶æ…‹æ›´æ–°å®Œäº†: isRecording = true')
      
      // éŒ²éŸ³é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆæ­£ç¢ºãªDurationè¨ˆç®—ã®ãŸã‚ï¼‰
      recordingStartTimeRef.current = Date.now()
      pausedTimeRef.current = 0 // ä¸€æ™‚åœæ­¢æ™‚é–“ã‚’ãƒªã‚»ãƒƒãƒˆ
      console.log('Recording started at:', new Date(recordingStartTimeRef.current).toISOString())
      
      console.log('ğŸ“ æ–°ã—ã„å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«æˆé•·ãƒ¢ãƒ‡ãƒ«ã‚’é–‹å§‹')
      
      // ãƒ†ãƒ³ãƒãƒ©ãƒªãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã¯çµ±åˆã‚·ã‚¹ãƒ†ãƒ æº–å‚™æ™‚ã«æ—¢ã«è¨­å®šæ¸ˆã¿
      
      // æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã®ãŸã‚ã®å®šæœŸå®Ÿè¡Œã‚¿ã‚¤ãƒãƒ¼
      console.log('ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†é–‹å§‹ãƒã‚§ãƒƒã‚¯:', {
        enableTranscription,
        tempFolderPath,
        recordingFilename,
        realtimeProcessor: false
      })
      
      // é‡è¤‡å‰Šé™¤ï¼šä¸Šã§æ—¢ã«å‡¦ç†æ¸ˆã¿
      
      // å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ä¿æŒï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
      if (enableTranscription && tempFolderPath && recordingFilename && false) { // ç„¡åŠ¹åŒ–
        try {
          console.log('ğŸ“ å¾“æ¥ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†é–‹å§‹: 20ç§’é–“éš”ã§ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°')
          
          // ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
          const settings = await window.electronAPI.loadSettings()
          const saveFolder = settings.saveFolder
          const fullRecordingPath = `${saveFolder}\\${recordingFilename}`
          const absoluteTempPath = `${saveFolder}\\${tempFolderPath}`
          
          console.log(`ç›£è¦–ãƒ•ã‚©ãƒ«ãƒ€: ${absoluteTempPath}`)
          console.log(`å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: ${fullRecordingPath}`)
          
          let chunkCounter = 1
          
          // 20ç§’ã”ã¨ã«çœŸã®å·®åˆ†ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
          realtimeProcessingIntervalRef.current = window.setInterval(async () => {
            if (mediaRecorderRef.current?.state === 'recording' && trueDiffGeneratorRef.current) {
              try {
                // requestData()ã‚’å‘¼ã³å‡ºã—ã¦ondataavailableã‚’èƒ½å‹•çš„ã«ãƒˆãƒªã‚¬ãƒ¼
                mediaRecorderRef.current.requestData()
                
                // ondataavailableãŒå®Ÿè¡Œã•ã‚Œã‚‹ã®ã‚’å°‘ã—å¾…ã¤
                await new Promise(resolve => setTimeout(resolve, 300))
                
                // çœŸã®å·®åˆ†ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ãªã—ï¼‰
                if (trueDiffGeneratorRef.current.isReady()) {
                  const chunkResult = await trueDiffGeneratorRef.current.generateTrueDifferentialChunk()
                  
                  if (chunkResult && chunkResult.isNewData) {
                    console.log(`âœ… å·®åˆ†ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆå®Œäº†: ${chunkResult.chunkNumber} (${chunkResult.dataSize} bytes)`)
                    console.log(`ğŸ“Š å®Ÿæ™‚é–“: é–‹å§‹${chunkResult.startTime.toFixed(1)}s, é•·ã•${chunkResult.duration.toFixed(1)}s`)
                    if (chunkResult.filePath) {
                      console.log(`ğŸ“ è‡ªå‹•ä¿å­˜æ¸ˆã¿: ${chunkResult.filePath}`)
                      
                      // ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯  
                      try {
                        const fileSize = await window.electronAPI.getFileSize(chunkResult.filePath)
                        console.log(`ğŸ“ ä¿å­˜ç¢ºèª: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º ${fileSize} bytes`)
                      } catch (error) {
                        console.error(`âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç¢ºèªã‚¨ãƒ©ãƒ¼:`, error)
                      }
                    }
                  } else {
                    console.log(`ğŸ“ æ–°ã—ã„å·®åˆ†ãƒ‡ãƒ¼ã‚¿ãªã— - ã‚¹ã‚­ãƒƒãƒ—`)
                  }
                } else {
                  console.log(`ğŸ“ TrueDifferentialGeneratoræœªåˆæœŸåŒ– - ã‚¹ã‚­ãƒƒãƒ—`)
                }
              } catch (error) {
                console.error(`âŒ çœŸã®å·®åˆ†ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼:`, error)
              }
            } else {
              if (realtimeProcessingIntervalRef.current) {
                window.clearInterval(realtimeProcessingIntervalRef.current)
                realtimeProcessingIntervalRef.current = null
              }
            }
          }, 20000) // 20ç§’ã”ã¨
          
          console.log('ğŸ“ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™')
        } catch (realtimeError) {
          console.error('ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—é–‹å§‹ã‚¨ãƒ©ãƒ¼:', realtimeError)
        }
      } else {
        if (enableTranscription) {
          console.warn('âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—é–‹å§‹æ¡ä»¶ãŒæº€ãŸã•ã‚Œã¦ã„ã¾ã›ã‚“:', {
            enableTranscription,
            tempFolderPath,
            recordingFilename: recordingFilename || 'undefined',
            realtimeProcessor: false
          })
        } else {
          console.log('ğŸ“ éŒ²éŸ³ã®ã¿ãƒ¢ãƒ¼ãƒ‰: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’ã‚¹ã‚­ãƒƒãƒ—')
        }
      }
      
    } catch (error) {
      console.error('ğŸš¨ğŸš¨ğŸš¨ startRecordingé–¢æ•°å†…ã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ğŸš¨ğŸš¨ğŸš¨')
      console.error('âŒ éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error)
      console.error('âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°:', {
        name: error instanceof Error ? error.name : 'Unknown',
        message: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : 'No stack trace',
        inputType,
        selectedDevice,
        enableTranscription
      })
      
      const detailMessage = error instanceof Error ? error.message : String(error);
      
      const errorMessage = inputType === 'desktop' 
        ? `ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚\n${detailMessage}`
        : `ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚\n${detailMessage}`
      
      alert(errorMessage)
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼ (full):', error)
      
      // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚éŒ²éŸ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      resetRecordingState()
      
      // ã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚‚éŒ²éŸ³ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
      const removeRecordingFileEntry = async () => {
        try {
          const settings = await window.electronAPI.loadSettings()
          const defaultFolder = settings.saveFolder
          
          // æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¦éŒ²éŸ³ãƒ•ãƒ©ã‚°ã‚’falseã«æ›´æ–°
          const currentFiles = await window.electronAPI.getFileList(defaultFolder)
          const extendedFiles = await Promise.all(
            currentFiles.map(async (file) => {
              try {
                const hasTranscriptionFile = await window.electronAPI.checkTranscriptionExists(file.filepath)
                const transcriptionPath = hasTranscriptionFile 
                  ? await window.electronAPI.getTranscriptionPath(file.filepath)
                  : undefined
                
                return {
                  ...file,
                  hasTranscriptionFile,
                  transcriptionPath,
                  isRecording: false // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®éŒ²éŸ³ãƒ•ãƒ©ã‚°ã‚’falseã«è¨­å®š
                }
              } catch (error) {
                console.error(`æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªã‚¨ãƒ©ãƒ¼ (${file.filename}):`, error)
                return {
                  ...file,
                  hasTranscriptionFile: false,
                  transcriptionPath: undefined,
                  isRecording: false
                }
              }
            })
          )
          
          setFileList(extendedFiles)
          console.log('ğŸ“ éŒ²éŸ³ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆæ›´æ–°å®Œäº†')
          
        } catch (error) {
          console.error('éŒ²éŸ³ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆæ›´æ–°ã‚¨ãƒ©ãƒ¼:', error)
        }
      }
      
      removeRecordingFileEntry()
    }
  }, [inputType, selectedDevice, selectedDesktopSource, selectedSystemDevice, resetRecordingState])
  
  // éŒ²éŸ³åœæ­¢
  const handleStopRecording = useCallback(async () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop())
      
      // ãƒã‚¤ã‚¯ç›£è¦–åœæ­¢
      if (micMonitorRef.current) {
        try {
          console.log('ğŸ¤ ãƒã‚¤ã‚¯ç›£è¦–ã‚’åœæ­¢ã—ã¾ã™...')
          micMonitorRef.current.stopMonitoring()
          micMonitorRef.current = null
          setMicStatus(null)
          setMicAlerts([])  // ãƒã‚¤ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆã‚‚ã‚¯ãƒªã‚¢
          console.log('âœ… ãƒã‚¤ã‚¯ç›£è¦–åœæ­¢å®Œäº†')
        } catch (micError) {
          console.error('âŒ ãƒã‚¤ã‚¯ç›£è¦–åœæ­¢ã‚¨ãƒ©ãƒ¼:', micError)
        }
      }
      
      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã®ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
      if (realtimeProcessingIntervalRef.current) {
          clearTimeout(realtimeProcessingIntervalRef.current); // clearTimeoutã«å¤‰æ›´
          realtimeProcessingIntervalRef.current = null;
        }
      // if (realtimeProcessingIntervalRef.current) {
      //   window.clearInterval(realtimeProcessingIntervalRef.current)
      //   realtimeProcessingIntervalRef.current = null
      // }
      
      // FileBasedRealtimeProcessorã‚’åœæ­¢
      if (realtimeProcessorRef.current) {
        try {
          console.log('ğŸ¬ FileBasedRealtimeProcessoråœæ­¢ä¸­...')
          
          // åœæ­¢å‰ã«æœ€çµ‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚’å®Ÿè¡Œ
          console.log('ğŸ’¾ æœ€çµ‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜ä¸­...')
          await realtimeProcessorRef.current.saveToFile()
          console.log('âœ… æœ€çµ‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜å®Œäº†')
          
          await realtimeProcessorRef.current.stop()
          console.log('âœ… FileBasedRealtimeProcessoråœæ­¢å®Œäº†')
        } catch (realtimeError) {
          console.error('âŒ FileBasedRealtimeProcessoråœæ­¢ã‚¨ãƒ©ãƒ¼:', realtimeError)
        }
      }
      
      // TrueDifferentialChunkGeneratorã‚’åœæ­¢ & ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«çµåˆ
      if (trueDiffGeneratorRef.current) {
        try {
          console.log('ğŸ”§ TrueDifferentialChunkGeneratoråœæ­¢ä¸­...')
          trueDiffGeneratorRef.current.stopRecording()
          console.log('âœ… TrueDifferentialChunkGeneratoråœæ­¢å®Œäº†')
          
          // Phase 3: ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«çµåˆå‡¦ç†
          const combinationStats = trueDiffGeneratorRef.current.getCombinationStats()
          console.log('ğŸ“Š ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«çµåˆçµ±è¨ˆ:', combinationStats)
          
          if (combinationStats.totalChunks > 0) {
            console.log('ğŸ”— ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«çµåˆé–‹å§‹...')
            
            try {
              const combinedBlob = await trueDiffGeneratorRef.current.generateCombinedWebMFile()
              
              if (combinedBlob) {
                // çµåˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19)
                const combinedFilename = `combined_${timestamp}.webm`
                
                const combinedBuffer = await combinedBlob.arrayBuffer()
                await window.electronAPI.saveFile(combinedBuffer, combinedFilename)
                
                console.log(`âœ… ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«çµåˆå®Œäº†: ${combinedFilename}`)
                console.log(`ğŸ“Š çµåˆçµ±è¨ˆ: ${combinationStats.totalChunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯, ç·æ™‚é–“${combinationStats.totalDuration.toFixed(1)}ç§’, ã‚µã‚¤ã‚º${combinedBlob.size}bytes`)
              } else {
                console.warn('âš ï¸ ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«çµåˆã§ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ')
              }
              
            } catch (combineError) {
              console.error('âŒ ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«çµåˆã‚¨ãƒ©ãƒ¼:', combineError)
            }
          } else {
            console.log('ğŸ“ çµåˆå¯èƒ½ãªãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“')
          }
          
        } catch (chunkError) {
          console.error('âŒ TrueDifferentialChunkGeneratoråœæ­¢ã‚¨ãƒ©ãƒ¼:', chunkError)
        }
      }
      
      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™
      console.log('ğŸ“ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™')
      
      // ãƒŸã‚­ã‚·ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
      if (audioMixingServiceRef.current) {
        try {
          console.log('ğŸ›ï¸ ãƒŸã‚­ã‚·ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢...')
          await audioMixingServiceRef.current.cleanup()
          audioMixingServiceRef.current = null
          setAudioLevels({ microphoneLevel: 0, desktopLevel: 0, mixedLevel: 0 })
          console.log('âœ… ãƒŸã‚­ã‚·ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢å®Œäº†')
        } catch (mixingError) {
          console.error('âŒ ãƒŸã‚­ã‚·ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ã‚¨ãƒ©ãƒ¼:', mixingError)
        }
      }
    }
  }, [isRecording])
  
  // éŒ²éŸ³ä¸€æ™‚åœæ­¢ãƒ»å†é–‹
  const handlePauseRecording = useCallback(() => {
    if (mediaRecorderRef.current) {
      if (isPaused) {
        // å†é–‹æ™‚ï¼šç¾åœ¨ã®æ™‚åˆ»ã‚’è¨˜éŒ²
        const resumeTime = Date.now()
        mediaRecorderRef.current.resume()
        setIsPaused(false)
        console.log('Recording resumed at:', new Date(resumeTime).toISOString())
      } else {
        // ä¸€æ™‚åœæ­¢æ™‚ï¼šä¸€æ™‚åœæ­¢æ™‚é–“ã‚’è¨ˆç®—ã—ã¦ç´¯è¨ˆã«è¿½åŠ 
        const pauseStartTime = Date.now()
        mediaRecorderRef.current.pause()
        setIsPaused(true)
        console.log('Recording paused at:', new Date(pauseStartTime).toISOString())
        
        // ä¸€æ™‚åœæ­¢æ™‚é–“ã‚’è¨˜éŒ²ï¼ˆå†é–‹æ™‚ã«è¨ˆç®—ã•ã‚Œã‚‹ï¼‰
        setTimeout(() => {
          if (isPaused) {
            const pauseEndTime = Date.now()
            pausedTimeRef.current += pauseEndTime - pauseStartTime
            console.log('Paused duration so far:', pausedTimeRef.current, 'ms')
          }
        }, 100)
      }
    }
  }, [isPaused])
  
  // å‰Šé™¤: handleTranscribe, handleConvertToMP3 ã¯ä¸è¦

  

  return (
    <div className="bottom-panel">
      <div className="bottom-panel__content">
        {/* å…¥åŠ›ã‚¿ã‚¤ãƒ—é¸æŠ */}
        <div className="flex items-center gap-md">
          <label className="text-secondary" style={{ minWidth: '100px' }}>å…¥åŠ›ã‚¿ã‚¤ãƒ—:</label>
          <select 
            className="select"
            value={inputType}
            onChange={(e) => setInputType(e.target.value as 'microphone' | 'desktop' | 'stereo-mix' | 'mixing')}
            disabled={isRecording}
            style={{ 
              width: '200px',
              opacity: isRecording ? 0.5 : 1
            }}
          >
            <option value="microphone">ğŸ¤ ãƒã‚¤ã‚¯éŸ³å£°</option>
            <option value="desktop">ğŸ–¥ï¸ ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°</option>
            <option value="stereo-mix">ğŸ”Š ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹</option>
            <option value="mixing">ğŸ›ï¸ ãƒŸã‚­ã‚·ãƒ³ã‚°</option>
          </select>
          {inputType === 'desktop' && (
            <div className="text-secondary" style={{ fontSize: '11px' }}>
              â€»ç”»é¢å…±æœ‰ã§ã€Œã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚’å…±æœ‰ã€ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„
              <br />
              âš ï¸ ãƒã‚¤ã‚¯éŸ³å£°ã‚‚æ··å…¥ã™ã‚‹å ´åˆã¯ã€WindowséŸ³å£°è¨­å®šã§ãƒã‚¤ã‚¯ã®ã€Œèãã€ã‚’ç„¡åŠ¹ã«ã—ã¦ãã ã•ã„
            </div>
          )}
          {inputType === 'stereo-mix' && (
            <div className="text-secondary" style={{ fontSize: '11px' }}>
              â€»ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã®ã¿ã‚’éŒ²éŸ³ã—ã¾ã™ã€‚ãƒã‚¤ã‚¯éŸ³å£°ã‚‚å«ã‚€å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
            </div>
          )}
          {inputType === 'mixing' && (
            <div className="text-secondary" style={{ fontSize: '11px' }}>
              â€»ãƒã‚¤ã‚¯éŸ³å£°ã¨ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°ã‚’åŒæ™‚ã«éŒ²éŸ³ã—ã¾ã™ã€‚
            </div>
          )}
        </div>

        {/* å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹é¸æŠï¼ˆãƒã‚¤ã‚¯ã®å ´åˆã®ã¿ï¼‰ */}
        {inputType === 'microphone' && (
          <div className="flex items-center gap-md">
            <label className="text-secondary" style={{ minWidth: '100px' }}>å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹:</label>
            <select 
              className="select flex-1"
              value={selectedDevice}
              onChange={(e) => setSelectedDevice(e.target.value)}
              disabled={isRecording}
              style={{ opacity: isRecording ? 0.5 : 1 }}
            >
              {availableDevices.map(device => (
                <option key={device.deviceId} value={device.deviceId}>
                  {device.label || `ãƒã‚¤ã‚¯ ${device.deviceId.slice(0, 8)}`}
                </option>
              ))}
            </select>
          </div>
        )}

        {/* ãƒã‚¤ã‚¯ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºï¼ˆéŒ²éŸ³ä¸­ã®ãƒã‚¤ã‚¯ã®å ´åˆã®ã¿ï¼‰ */}
        {inputType === 'microphone' && isRecording && micStatus && (
          <div className="flex items-center gap-md">
            <label className="text-secondary" style={{ minWidth: '100px' }}>éŸ³å£°ãƒ¬ãƒ™ãƒ«:</label>
            <div className="flex items-center gap-sm flex-1">
              {/* éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒãƒ¼ */}
              <div 
                style={{
                  width: '200px',
                  height: '20px',
                  backgroundColor: '#333',
                  borderRadius: '10px',
                  overflow: 'hidden',
                  border: '1px solid #555',
                  position: 'relative'
                }}
              >
                {/* éŸ³å£°ãƒ¬ãƒ™ãƒ«ï¼ˆç·‘ï½é»„ï½èµ¤ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ */}
                <div
                  style={{
                    width: `${micStatus.inputLevel}%`,
                    height: '100%',
                    backgroundColor: micStatus.inputLevel < 30 ? '#4CAF50' : 
                                     micStatus.inputLevel < 70 ? '#FF9800' : '#F44336',
                    transition: 'width 0.1s ease-out'
                  }}
                />
                {/* ãƒ”ãƒ¼ã‚¯ãƒ¬ãƒ™ãƒ«ãƒ©ã‚¤ãƒ³ */}
                <div
                  style={{
                    position: 'absolute',
                    left: `${micStatus.peakLevel}%`,
                    top: 0,
                    width: '2px',
                    height: '100%',
                    backgroundColor: '#fff',
                    transition: 'left 0.1s ease-out'
                  }}
                />
              </div>
              
              {/* æ•°å€¤è¡¨ç¤º */}
              <div style={{ 
                fontSize: '12px', 
                minWidth: '60px',
                color: micStatus.inputLevel < 5 ? '#F44336' : 
                       micStatus.inputLevel < 15 ? '#FF9800' : '#4CAF50'
              }}>
                {micStatus.inputLevel}%
              </div>
              
              {/* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¢ã‚¤ã‚³ãƒ³ */}
              <div style={{ fontSize: '14px' }}>
                {micStatus.isSilent ? 'ğŸ”‡' : 
                 micStatus.inputLevel < 15 ? 'ğŸ”‰' : 
                 micStatus.inputLevel < 50 ? 'ğŸ”Š' : 'ğŸ“¢'}
              </div>
            </div>
          </div>
        )}

        {/* ãƒã‚¤ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º */}
        {micAlerts.length > 0 && micAlerts.slice(-1).map((alert, index) => (
          <div key={index} className="flex items-center gap-md">
            <label className="text-secondary" style={{ minWidth: '100px' }}>âš ï¸ éŸ³å£°è¨ºæ–­:</label>
            <div style={{ 
              fontSize: '12px',
              color: alert.severity === 'error' ? '#F44336' : 
                     alert.severity === 'warning' ? '#FF9800' : '#2196F3',
              flex: 1
            }}>
              {alert.message}
              {alert.recommendation && (
                <div style={{ fontSize: '11px', color: '#888', marginTop: '2px' }}>
                  ğŸ’¡ {alert.recommendation}
                </div>
              )}
            </div>
          </div>
        ))}

        {/* ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚½ãƒ¼ã‚¹é¸æŠï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã®å ´åˆã®ã¿ï¼‰ */}
        {inputType === 'desktop' && (
          <>
            <div className="flex items-center gap-md">
              <label className="text-secondary" style={{ minWidth: '100px' }}>ã‚­ãƒ£ãƒ—ãƒãƒ£å¯¾è±¡:</label>
              <select 
                className="select flex-1"
                value={selectedDesktopSource}
                onChange={(e) => setSelectedDesktopSource(e.target.value)}
                disabled={isRecording}
              style={{ opacity: isRecording ? 0.5 : 1 }}
            >
              <option value="">é¸æŠã—ã¦ãã ã•ã„</option>
              {desktopSources.map(source => (
                <option key={source.id} value={source.id}>
                  {source.name}
                </option>
              ))}
            </select>
            {desktopSources.length === 0 && (
              <div className="text-secondary" style={{ fontSize: '11px' }}>
                ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚½ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­...
              </div>
            )}
          </div>
        </>
        )}
        
        {/* ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹é¸æŠï¼ˆã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹ã®å ´åˆã®ã¿ï¼‰ */}
        {inputType === 'stereo-mix' && (
          <div className="flex items-center gap-md">
            <label className="text-secondary" style={{ minWidth: '100px' }}>ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹:</label>
            <select 
              className="select flex-1"
              value={selectedSystemDevice}
              onChange={(e) => setSelectedSystemDevice(e.target.value)}
              disabled={isRecording}
              style={{ opacity: isRecording ? 0.5 : 1 }}
            >
              <option value="">é¸æŠã—ã¦ãã ã•ã„</option>
              {systemAudioDevices.map(device => (
                <option key={device.deviceId} value={device.deviceId}>
                  {device.label || `ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒã‚¤ã‚¹ ${device.deviceId.slice(0, 8)}`}
                </option>
              ))}
            </select>
            {systemAudioDevices.length === 0 && (
              <div className="text-secondary" style={{ fontSize: '11px' }}>
                ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Windowsè¨­å®šã§ã‚¹ãƒ†ãƒ¬ã‚ªãƒŸãƒƒã‚¯ã‚¹ã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚
              </div>
            )}
          </div>
        )}
        
        {/* ãƒŸã‚­ã‚·ãƒ³ã‚°è¨­å®šï¼ˆãƒŸã‚­ã‚·ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿ï¼‰ */}
        {inputType === 'mixing' && (
          <div className="mixing-panel">
            <h4 className="mixing-panel__title">ğŸ›ï¸ ãƒŸã‚­ã‚·ãƒ³ã‚°è¨­å®š</h4>
            
            {/* ãƒã‚¤ã‚¯éŸ³å£°è¨­å®š */}
            <div className="mixing-panel__row">
              <label className="mixing-panel__checkbox-group">
                <input 
                  type="checkbox" 
                  checked={mixingConfig.enableMicrophone}
                  onChange={(e) => setMixingConfig(prev => ({ ...prev, enableMicrophone: e.target.checked }))}
                  disabled={isRecording}
                />
                <span className="text-secondary">ğŸ¤ ãƒã‚¤ã‚¯éŸ³å£°ã‚’å«ã‚ã‚‹</span>
              </label>
              {mixingConfig.enableMicrophone && (
                <select 
                  className="select mixing-panel__device-select"
                  value={selectedDevice}
                  onChange={(e) => setSelectedDevice(e.target.value)}
                  disabled={isRecording}
                  style={{ opacity: isRecording ? 0.5 : 1 }}
                >
                  {availableDevices.map(device => (
                    <option key={device.deviceId} value={device.deviceId}>
                      {device.label || `ãƒã‚¤ã‚¯ ${device.deviceId.slice(0, 8)}`}
                    </option>
                  ))}
                </select>
              )}
            </div>
            
            {/* ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°è¨­å®š */}
            <div className="mixing-panel__row">
              <label className="mixing-panel__checkbox-group">
                <input 
                  type="checkbox" 
                  checked={mixingConfig.enableDesktop}
                  onChange={(e) => setMixingConfig(prev => ({ ...prev, enableDesktop: e.target.checked }))}
                  disabled={isRecording}
                />
                <span className="text-secondary">ğŸ–¥ï¸ ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—éŸ³å£°ã‚’å«ã‚ã‚‹</span>
              </label>
              {mixingConfig.enableDesktop && (
                <select 
                  className="select mixing-panel__device-select"
                  value={selectedDesktopSource}
                  onChange={(e) => setSelectedDesktopSource(e.target.value)}
                  disabled={isRecording}
                  style={{ opacity: isRecording ? 0.5 : 1 }}
                >
                  <option value="">é¸æŠã—ã¦ãã ã•ã„</option>
                  {desktopSources.map(source => (
                    <option key={source.id} value={source.id}>
                      {source.name}
                    </option>
                  ))}
                </select>
              )}
            </div>
            
            {/* éŸ³å£°ãƒ¬ãƒ™ãƒ«èª¿æ•´ */}
            {!isRecording && (
              <div className="mixing-panel__gain-controls">
                <div className="mixing-panel__gain-group">
                  <label className="mixing-panel__gain-label">ãƒã‚¤ã‚¯:</label>
                  <input 
                    type="range" 
                    min="0" 
                    max="1" 
                    step="0.1"
                    value={mixingConfig.microphoneGain}
                    onChange={(e) => setMixingConfig(prev => ({ ...prev, microphoneGain: parseFloat(e.target.value) }))}
                    className="mixing-panel__gain-slider"
                  />
                  <span className="mixing-panel__gain-value">
                    {Math.round(mixingConfig.microphoneGain * 100)}%
                  </span>
                </div>
                <div className="mixing-panel__gain-group">
                  <label className="mixing-panel__gain-label">ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—:</label>
                  <input 
                    type="range" 
                    min="0" 
                    max="1" 
                    step="0.1"
                    value={mixingConfig.desktopGain}
                    onChange={(e) => setMixingConfig(prev => ({ ...prev, desktopGain: parseFloat(e.target.value) }))}
                    className="mixing-panel__gain-slider"
                  />
                  <span className="mixing-panel__gain-value">
                    {Math.round(mixingConfig.desktopGain * 100)}%
                  </span>
                </div>
              </div>
            )}
            
            {/* ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºï¼ˆéŒ²éŸ³ä¸­ã®ã¿ï¼‰ */}
            {isRecording && (
              <div className="mixing-panel__levels">
                <div className="mixing-panel__levels-title">ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒ¬ãƒ™ãƒ«:</div>
                <div className="mixing-panel__level-row">
                  <div className="mixing-panel__level-group">
                    <span className="mixing-panel__level-label">ãƒã‚¤ã‚¯:</span>
                    <div className="mixing-panel__level-bar">
                      <div 
                        className={`mixing-panel__level-fill ${
                          audioLevels.microphoneLevel > 0.8 ? 'mixing-panel__level-fill--high' : 
                          audioLevels.microphoneLevel > 0.5 ? 'mixing-panel__level-fill--medium' : 
                          'mixing-panel__level-fill--low'
                        }`}
                        style={{ width: `${audioLevels.microphoneLevel * 100}%` }}
                      />
                    </div>
                    <span className="mixing-panel__level-value">
                      {Math.round(audioLevels.microphoneLevel * 100)}%
                    </span>
                  </div>
                  <div className="mixing-panel__level-group">
                    <span className="mixing-panel__level-label">ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—:</span>
                    <div className="mixing-panel__level-bar">
                      <div 
                        className={`mixing-panel__level-fill ${
                          audioLevels.desktopLevel > 0.8 ? 'mixing-panel__level-fill--high' : 
                          audioLevels.desktopLevel > 0.5 ? 'mixing-panel__level-fill--medium' : 
                          'mixing-panel__level-fill--low'
                        }`}
                        style={{ width: `${audioLevels.desktopLevel * 100}%` }}
                      />
                    </div>
                    <span className="mixing-panel__level-value">
                      {Math.round(audioLevels.desktopLevel * 100)}%
                    </span>
                  </div>
                </div>
              </div>
            )}
          </div>
        )}
        
        {/* éŒ²éŸ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« */}
        <div className="flex items-center gap-md">
          <div className="flex gap-sm">
            {!isRecording ? (
              <>
                <button 
                  className="btn btn--success"
                  onClick={handleStartRecordingWithTranscription}
                  disabled={
                    (inputType === 'microphone' && !selectedDevice) ||
                    (inputType === 'desktop' && !selectedDesktopSource) ||
                    (inputType === 'stereo-mix' && !selectedSystemDevice) ||
                    (inputType === 'mixing' && !mixingConfig.enableMicrophone && !mixingConfig.enableDesktop) ||
                    (inputType === 'mixing' && mixingConfig.enableMicrophone && !selectedDevice) ||
                    (inputType === 'mixing' && mixingConfig.enableDesktop && !selectedDesktopSource)
                  }
                >
                  â— éŒ²éŸ³ãƒ»æ–‡å­—èµ·ã“ã—
                </button>
                <button 
                  className="btn btn--secondary"
                  onClick={handleStartRecordingOnly}
                  disabled={
                    (inputType === 'microphone' && !selectedDevice) ||
                    (inputType === 'desktop' && !selectedDesktopSource) ||
                    (inputType === 'stereo-mix' && !selectedSystemDevice) ||
                    (inputType === 'mixing' && !mixingConfig.enableMicrophone && !mixingConfig.enableDesktop) ||
                    (inputType === 'mixing' && mixingConfig.enableMicrophone && !selectedDevice) ||
                    (inputType === 'mixing' && mixingConfig.enableDesktop && !selectedDesktopSource)
                  }
                >
                  â— éŒ²éŸ³ã®ã¿
                </button>
              </>
            ) : (
              <>
                <button 
                  className="btn btn--error"
                  onClick={handleStopRecording}
                >
                  â–  åœæ­¢
                </button>
                <button 
                  className="btn"
                  onClick={handlePauseRecording}
                >
                  {isPaused ? 'â–¶ å†é–‹' : 'â¸ ä¸€æ™‚åœæ­¢'}
                </button>
              </>
            )}
          </div>
          
          <div className="text-secondary">
            éŒ²éŸ³æ™‚é–“: <span className="text-primary">{formatTime(recordingTime)}</span>
          </div>
          
          {isRecording && (
            <div className="text-success">
              {isPaused ? 'â¸ ä¸€æ™‚åœæ­¢ä¸­' : 'â— éŒ²éŸ³ä¸­'}
            </div>
          )}
        </div>
        
      </div>
    </div>
  )
}

export default BottomPanel

