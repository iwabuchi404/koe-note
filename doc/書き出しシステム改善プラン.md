## 【第1段階 実行計画書】`timeslice`の技術的障壁の特定とヘッダー再構築によるチャンク修復プラン

### 1. 目的とゴール

本計画の目的は、`KoeNote`が直面している「デスクトップ音声録音における`timeslice`機能の不全」という根本的な技術障壁の原因を特定し、それを前提とした上で、**現状の手動分割アーキテクチャを維持しつつ、破損チャンクファイルを修復し文字起こし成功率を最大化する**ことです。

#### **ゴール**
*   **原因の特定:** `timeslice`が正常に機能しない原因が、`getDisplayMedia`由来のストリームの特殊性にあることを明確にする。
*   **破損ファイルの修復:** 手動分割された後続チャンクに対し、再生メタデータ（特に`Cues`）を除去した「軽量ヘッ"ダー」を結合することで、ファイルの構造的矛盾を緩和する。
*   **成功率の向上:** `End of file`エラーの発生率を大幅に引き下げ、文字起こし成功率を現状の約60%から**80%以上**に安定させることを目指す。

#### **対象外（この段階では解決しない課題）**
*   **ファイルの再生可能性:** 本プランで修復されたチャンクは、あくまで音声認識エンジンが「読み取りやすくなる」ことを目的としており、メディアプレイヤーでの**正常な再生・シークは保証しません。**
*   **音声の欠落（ギャップ）:** `MediaRecorder`を都度`stop`/`start`する方式を採用した場合、チャンク間に微小な音声の欠落が発生する可能性があります。

---

### 2. `timeslice`が機能しない根本原因の分析

これまでの検証（マイク音声とデスクトップ音声のストリーム設定比較、Web Audio API経由での録音失敗）から、問題は単純なAPIの使い方の誤りではないことが判明しています。

**結論として、`timeslice`が機能しない原因は以下の複合的な要因によるものと断定します。**

1.  **`getDisplayMedia`由来のストリームの不安定性:**
    `getDisplayMedia`で取得されるデスクトップ音声トラックは、`getSettings()`で表示されるサンプルレート等の表面的なパラメータが正常であっても、内部的なデータフロー（バッファリング、パケットのタイミング等）がマイク入力とは異なり、不安定である可能性が高いです。

2.  **`MediaRecorder`の内部エンコーダーとの非互換性:**
    ブラウザ（Electron/Chromium）に内蔵されている`MediaRecorder`のWebM/Opusエンコーダーは、この`getDisplayMedia`からの特殊なストリームを`timeslice`で区切る（＝ヘッダーを動的に生成し、ストリームを閉じてから再開する）処理を想定しておらず、結果としてヘッダー情報が欠落・破損した、再生不可能なBlobを生成してしまいます。

3.  **既知のブラウザ実装の問題:**
    AIによる調査レポートが示す通り、これは`MediaRecorder` APIの既知の制約や、特定のブラウザバージョンに存在するバグである可能性も否定できません。（例: Chrome bug #642012）

**この問題はアプリケーションレイヤーでの完全な解決が困難であるため、`timeslice`機能に依存しない現在の「手動分割」アプローチを継続し、その出力ファイルを修復する方針が最も現実的です。**

---

### 3. 【第1段階】ヘッダー再構築によるチャンク修復の実装プラン

このプランは、VADを導入せず、現在の時間ベース（またはサイズベース）の手動分割ロジックをそのまま使用することを前提とします。

**実装戦略:**
録音開始時に一度だけ生成されるチャンク1の完全なヘッダーから、後続チャンクとの矛盾を引き起こす**有害なメタデータ（`Cues`）をプログラム的に除去**します。この「軽量化」されたヘッダーを、2つ目以降の生の音声データチャンクに結合することで、音声認識エンジンがファイルを解析できる確率を高めます。

**推奨ライブラリ:** **`ts-ebml`**
JavaScript/TypeScript環境でWebMファイルの基礎構造であるEBMLを柔軟に読み書きできる唯一の現実的な選択肢です。

#### **実装ステップ**

**ステップ1: `WebMRepairKit`クラスの作成**
以下の機能を持つヘルパークラスを作成します。これはアプリケーションの録音セッション中で単一のインスタンスとして利用します。

**`WebMRepairKit.ts`**
```typescript
import { Decoder, Encoder } from 'ts-ebml';

/**
 * 手動分割されたWebMチャンクを修復するためのユーティリティクラス。
 * 最初のチャンクから軽量ヘッダーを抽出し、後続チャンクに結合する。
 */
export class WebMRepairKit {
    private lightHeader: Uint8Array | null = null;
    private decoder = new Decoder();
    private encoder = new Encoder();

    /**
     * 最初のチャンクBlobから、有害なメタデータ（Cues, Cluster）を除去した
     * 「軽量ヘッダー」を生成し、インスタンス内に保持する。
     * このメソッドは録音セッションの最初に一度だけ呼び出す。
     * @param firstChunkBlob 録音開始直後に生成された最初のチャンクデータ
     */
    public async initializeHeader(firstChunkBlob: Blob): Promise<void> {
        try {
            const buffer = await firstChunkBlob.arrayBuffer();
            const elements = this.decoder.decode(buffer);

            // Cues（シーク情報）とCluster（実際の音声データ）を除いた要素のみを抽出
            const headerElements = elements.filter(el => 
                el.name !== 'Cues' && el.name !== 'Cluster'
            );
            
            // 抽出した要素から新しいヘッダーをバイナリとして再生成
            this.lightHeader = this.encoder.encode(headerElements);
            console.log(`[WebMRepairKit] 軽量ヘッダーを生成しました。サイズ: ${this.lightHeader.byteLength} bytes`);

        } catch (e) {
            console.error("[WebMRepairKit] ヘッダーの解析または生成に失敗しました:", e);
            this.lightHeader = null; // 失敗した場合はヘッダーを無効化
        }
    }

    /**
     * 2番目以降の（ヘッダーを持たない）チャンクBlobに、
     * 保持している軽量ヘッダーを結合して修復する。
     * @param rawChunkBlob ヘッダーのない生の音声データチャンク
     * @returns 修復された新しいBlobオブジェクト
     */
    public async repairChunk(rawChunkBlob: Blob): Promise<Blob> {
        if (!this.lightHeader) {
            console.warn("[WebMRepairKit] ヘッダーが未初期化のため、チャンクを修復できません。");
            return rawChunkBlob; // ヘッダーがない場合は何もせず返す
        }
        
        const chunkBuffer = await rawChunkBlob.arrayBuffer();
        
        // 新しいUint8Arrayを作成し、ヘッダーとチャンクデータを結合する
        const repairedBuffer = new Uint8Array(this.lightHeader.length + chunkBuffer.byteLength);
        repairedBuffer.set(this.lightHeader, 0);
        repairedBuffer.set(new Uint8Array(chunkBuffer), this.lightHeader.length);
        
        return new Blob([repairedBuffer], { type: 'audio/webm' });
    }
}
```

**ステップ2: 既存の録音ロジックへの統合**
現在の録音処理フローに、`WebMRepairKit`を組み込みます。

**コードイメージ (`useKoeNoteRecorder.ts` などの想定):**
```typescript
// ... imports ...
import { WebMRepairKit } from './WebMRepairKit';

// ... カスタムフックやクラスの内部 ...

// 録音セッションごとに新しいインスタンスを作成
const repairKit = new WebMRepairKit();
let isHeaderInitialized = false;

// MediaRecorderの ondataavailable または手動分割処理
async function handleChunk(chunkBlob: Blob) {
    if (!isHeaderInitialized) {
        // 最初のチャンク
        await repairKit.initializeHeader(chunkBlob);
        isHeaderInitialized = true;
        
        // 最初のチャンクは修復の必要がない（または修復済みヘッダー版を送るか選択）
        // そのままサーバーに送信
        sendChunkToTranscriptionServer(chunkBlob);

    } else {
        // 2番目以降のチャンク
        const repairedChunk = await repairKit.repairChunk(chunkBlob);
        
        // 修復されたチャンクをサーバーに送信
        sendChunkToTranscriptionServer(repairedChunk);
    }
}
```

---

### 4. まとめと次のステップ

この第1段階プランは、`timeslice`が利用できないという厳しい制約の中で、現状の資産を最大限に活かし、文字起こしの安定性を向上させるための最も合理的で現実的なアプローチです。

**このプランを実行することで期待できること:**
*   音声認識エンジンが混乱する最大の原因であった`Cues`メタデータとの矛盾がなくなり、`End of file`エラーが大幅に減少します。
*   結果として、文字起こしの成功率が安定し、ユーザー体験が向上します。

**残る課題:**
*   **再生不可能性:** この方法で生成したファイルは、あくまで「機械（Whisper）が読みやすいデータ」であり、「人間が再生できるメディアファイル」ではありません。この点は明確な技術的限界として認識しておく必要があります。
*   **根本解決ではない:** あくまで応急処置であり、ブラウザのアップデート等で挙動が変わるリスクは残ります。

**次のステップ:**
1.  `ts-ebml`ライブラリをプロジェクトに導入します。
2.  `WebMRepairKit`クラスを実装し、既存の録音・チャンク分割ロジックに組み込みます。
3.  実際にデスクトップ音声で長時間録音を行い、文字起こしの成功率が目標値（80%以上）まで改善したかを確認します。

この第1段階で安定稼働を実現した後、より完璧なソリューションである**第2段階（ffmpeg.wasmによる完全なファイル再構築）**への移行を計画することが、`KoeNote`の品質をさらに高めるための理想的なロードマップとなります。